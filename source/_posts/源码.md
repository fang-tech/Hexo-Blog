



## SparkListenerSQLExecutionEnd
```scala
case class SparkListenerSQLExecutionEnd(
    executionId: Long,
    time: Long,
    // For backward compatibility, the `errorMessage` will be None when we parse event logs
    // generated by old versions of Spark. It should always be Some in Spark 3.4+ and empty string
    // means there is no error during execution.
    errorMessage: Option[String] = None)
  extends SparkListenerEvent {

  // The name of the execution, e.g. `df.collect` will trigger a SQL execution with name "collect".
  @JsonIgnore private[sql] var executionName: Option[String] = None

  // The following 3 fields are only accessed when `executionName` is defined.

  // The duration of the SQL execution, in nanoseconds.
  @JsonIgnore private[sql] var duration: Long = 0L

  // The `QueryExecution` instance that represents the SQL execution
  @JsonIgnore private[sql] var qe: QueryExecution = null

  // The exception object that caused this execution to fail. None if the execution doesn't fail.
  @JsonIgnore private[sql] var executionFailure: Option[Throwable] = None
}
```
## SparkListenerSQLExecutionStart
```scala
case class SparkListenerSQLExecutionStart(
    executionId: Long,
    // if the execution is a root, then rootExecutionId == executionId
    // if the event is parsed from the event log that generated by Spark not support
    // nested execution, then rootExecutionId = None
    @JsonDeserialize(contentAs = classOf[java.lang.Long])
    rootExecutionId: Option[Long],
    description: String,
    details: String,
    physicalPlanDescription: String,
    sparkPlanInfo: SparkPlanInfo,
    time: Long,
    modifiedConfigs: Map[String, String] = Map.empty,
    jobTags: Set[String] = Set.empty)
  extends SparkListenerEvent
```
## processAnyEvent
```scala

```def processAnyEvent(event: SparkListenerEvent): Unit = {
    event match {
      // === 日志和系统事件 ===
      case _: SparkListenerLogStart =>
        doSparkListenerLogStart(app, event.asInstanceOf[SparkListenerLogStart])
        
      // === 存储管理事件 ===
      case _: SparkListenerBlockManagerAdded =>
        doSparkListenerBlockManagerAdded(app,
          event.asInstanceOf[SparkListenerBlockManagerAdded])
      case _: SparkListenerBlockManagerRemoved =>
        doSparkListenerBlockManagerRemoved(app,
          event.asInstanceOf[SparkListenerBlockManagerRemoved])
          
      // === 环境和应用生命周期事件 ===
      case _: SparkListenerEnvironmentUpdate =>
        doSparkListenerEnvironmentUpdate(app,
          event.asInstanceOf[SparkListenerEnvironmentUpdate])
      case _: SparkListenerApplicationStart =>
        doSparkListenerApplicationStart(app,
          event.asInstanceOf[SparkListenerApplicationStart])
      case _: SparkListenerApplicationEnd =>
        doSparkListenerApplicationEnd(app,
          event.asInstanceOf[SparkListenerApplicationEnd])
          
      // === 执行器生命周期事件 ===
      case _: SparkListenerExecutorAdded =>
        doSparkListenerExecutorAdded(app,
          event.asInstanceOf[SparkListenerExecutorAdded])
      case _: SparkListenerExecutorRemoved =>
        doSparkListenerExecutorRemoved(app,
          event.asInstanceOf[SparkListenerExecutorRemoved])
          
      // === 任务执行事件 ===
      case _: SparkListenerTaskStart =>
        doSparkListenerTaskStart(app,
          event.asInstanceOf[SparkListenerTaskStart])
      case _: SparkListenerTaskEnd =>
        doSparkListenerTaskEnd(app,
          event.asInstanceOf[SparkListenerTaskEnd])
      case _: SparkListenerTaskGettingResult =>
        doSparkListenerTaskGettingResult(app,
          event.asInstanceOf[SparkListenerTaskGettingResult])
          
      // === SQL 执行事件 ===
      case _: SparkListenerSQLExecutionStart =>
        doSparkListenerSQLExecutionStart(app,
          event.asInstanceOf[SparkListenerSQLExecutionStart])
      case _: SparkListenerSQLExecutionEnd =>
        doSparkListenerSQLExecutionEnd(app,
          event.asInstanceOf[SparkListenerSQLExecutionEnd])
      case _: SparkListenerDriverAccumUpdates =>
        doSparkListenerDriverAccumUpdates(app,
          event.asInstanceOf[SparkListenerDriverAccumUpdates])
          
      // === 作业和阶段执行事件 ===
      case _: SparkListenerJobStart =>
        doSparkListenerJobStart(app,
          event.asInstanceOf[SparkListenerJobStart])
      case _: SparkListenerJobEnd =>
        doSparkListenerJobEnd(app,
          event.asInstanceOf[SparkListenerJobEnd])
      case _: SparkListenerStageSubmitted =>
        doSparkListenerStageSubmitted(app,
          event.asInstanceOf[SparkListenerStageSubmitted])
      case _: SparkListenerStageCompleted =>
        doSparkListenerStageCompleted(app,
          event.asInstanceOf[SparkListenerStageCompleted])
          
      // === 自适应查询执行事件（AQE） ===
      case _: SparkListenerSQLAdaptiveExecutionUpdate =>
        doSparkListenerSQLAdaptiveExecutionUpdate(app,
          event.asInstanceOf[SparkListenerSQLAdaptiveExecutionUpdate])
      case _: SparkListenerSQLAdaptiveSQLMetricUpdates =>
        doSparkListenerSQLAdaptiveSQLMetricUpdates(app,
          event.asInstanceOf[SparkListenerSQLAdaptiveSQLMetricUpdates])
          
      // === 流处理事件 ===
      case _: StreamingQueryListener.QueryStartedEvent =>
        doSparkListenerStreamingQuery(app,
          event.asInstanceOf[StreamingQueryListener.QueryStartedEvent])
      case _: StreamingQueryListener.QueryTerminatedEvent =>
        doSparkListenerStreamingQuery(app,
          event.asInstanceOf[StreamingQueryListener.QueryTerminatedEvent])
          
      // === RAPIDS 特定事件 ===
      case _: SparkRapidsBuildInfoEvent =>
        doSparkRapidsBuildInfoEvent(app,
          event.asInstanceOf[SparkRapidsBuildInfoEvent])
          
      // === 未识别事件处理 ===
      case _ =>
        // 尝试通过反射处理 ResourceProfileAdded（版本兼容性处理）
        val wasResourceProfileAddedEvent = doSparkListenerResourceProfileAddedReflect(app, event)
        if (!wasResourceProfileAddedEvent) doOtherEvent(app, event)
    }
  }