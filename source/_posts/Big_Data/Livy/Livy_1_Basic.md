---
title: LivyåŸºç¡€çŸ¥è¯†
tags:
  - Livy
  - BigData
  - Spark
date: 2025-10-30
---
# æ¦‚å¿µç†è§£

## Livy è§£å†³äº†ä»€ä¹ˆé—®é¢˜ï¼Ÿä¸ºä»€ä¹ˆä¸ç›´æ¥ç”¨ spark-submitï¼Ÿ
è§£å†³äº†ç”¨æˆ·æäº¤sparkä»»åŠ¡çš„æ˜“ç”¨æ€§å’Œæ§åˆ¶æ€§é—®é¢˜, ä½¿ç”¨æˆ·èƒ½é€šè¿‡HTTPè¯·æ±‚å‘sparkæäº¤ä»»åŠ¡
- æƒé™é—®é¢˜: ä½¿ç”¨spark-submit, ç”¨æˆ·éœ€è¦ç™»é™†ä¸ŠæœåŠ¡å™¨, ä½¿ç”¨spark-submitå‘½ä»¤æäº¤, è¿™å°†sparkæ‰€åœ¨çš„æœåŠ¡å™¨çš„è®¿é—®æƒé™å’Œæäº¤sparkä»»åŠ¡çš„æƒé™ç»‘å®š, ä½†æ˜¯å®é™…ä¸Šæäº¤sparkä»»åŠ¡çš„roleå’Œè®¿é—®æœåŠ¡å™¨çš„roleåº”è¯¥æ˜¯åˆ†ç¦»çš„.
- æ˜“ç”¨æ€§é—®é¢˜: åœ¨è¿‡å»ç”¨æˆ·éœ€è¦åœ¨æœ¬åœ°å†™å¥½ä»£ç , é€šè¿‡SFTPä¸Šä¼ åˆ°æœåŠ¡å™¨ä¸Š, å†é€šè¿‡spark-submitæäº¤ä»»åŠ¡, ç°åœ¨ç”¨æˆ·å¯ä»¥é€šè¿‡jupyter + livyçš„æ–¹å¼, åœ¨æœ¬åœ°ç¼–å†™ä»£ç , åŠ¨æ€å˜æ›´å¹¶ä¸”éšæ—¶é€šè¿‡HTTPå‘Livyæäº¤ä»»åŠ¡
- è‡ªåŠ¨åŒ–é—®é¢˜: ç›´æ¥é€šè¿‡spark-submitæäº¤ä»»åŠ¡, æ— æ³•å¯¹äºsparkä»»åŠ¡è¿›è¡Œé›†ä¸­ç®¡ç†, æ•è·ä¸€äº›æŒ‡æ ‡, æˆ–è€…è¿›è¡Œé…ç½®è¦†ç›–ç­‰å…¶ä»–çš„è‡ªåŠ¨åŒ–çš„æ“ä½œ, Livyçš„å¼•å…¥ç›¸å½“äºä¸ºç”¨æˆ·å’Œspark-submitä¹‹é—´æ³¨å…¥äº†ä¸€ä¸ªç®¡ç†çš„ä¸­é—´å±‚

##  Livy æ”¯æŒå“ªå‡ ç§ Session ç±»å‹ï¼Ÿå®ƒä»¬çš„åŒºåˆ«æ˜¯ä»€ä¹ˆï¼Ÿ
### Session Type
åˆ†æˆ**Interactive Session**å’Œ**Batch Session**ä¸¤ç±»

- Interactive Session
	- äº¤äº’å¼Session
	- REST APIç«¯ç‚¹ /sessions
	- ç”¨æˆ·é€šè¿‡REST APIæäº¤**ä»£ç ç‰‡æ®µ**å¹¶äº¤äº’å¼æ‰§è¡Œ
	- æ”¯æŒå®æ—¶è·å–æ‰§è¡Œç»“æœ
	- ä¼šè¯é€šè¿‡å¿ƒè·³æœºåˆ¶æ£€æµ‹ä¼šè¯æ˜¯å¦å­˜æ´»
- Batch Session
	- REST APIç«¯ç‚¹ /batches
	- ç”¨äºæäº¤ä¸€ä¸ª**å®Œæ•´çš„sparkåº”ç”¨ç¨‹åº** (éœ€è¦æä¾› jar/py)
	- ä¸€æ¬¡æ€§æ‰§è¡Œ, æ‰§è¡Œå®Œåä¼šè¯ç»“æŸ
	- æ”¯æŒæŒ‡å®š main class å’Œå‘½ä»¤è¡Œå‚æ•°
	- é€‚åˆé•¿æ—¶é—´è¿è¡Œçš„æ‰¹å¤„ç†ä½œä¸š
### Session Kind
åˆ†æˆ**Spark**, **PySpark**, **SparkR**, **Shared**, **SQL**äº”ç§

- Spark/Scala: Scalaè¯­è¨€çš„äº¤äº’å¼å¯¹è¯
- PySpark/Python: Pythonè¯­è¨€çš„äº¤äº’å¼Sparkä¼šè¯
- Spark/R: Rè¯­è¨€çš„äº¤äº’å¼Sparkä¼šè¯
- SQL: äº¤äº’å¼SQL Sparkä¼šè¯
- Shared: å…±äº«ä¼šè¯ (ç‰¹æ®Šç±»å‹)

æ¯ä¸ª**äº¤äº’å¼å¯¹è¯**å¯ä»¥åŒæ—¶æ”¯æŒæ‰€æœ‰å››ç§è¯­è¨€è§£é‡Šå™¨
- åˆ›å»ºä¼šè¯çš„æ—¶å€™å¯ä»¥ä¸æŒ‡å®škind, è€Œæ˜¯åœ¨æäº¤è¯­å¥æ—¶æŒ‡å®š
- å¦‚æœåˆ›å»ºå¼æŒ‡å®šäº†kind, åˆ™ä¼šä½œä¸ºé»˜è®¤çš„è¯­è¨€
- å¯ä»¥åœ¨åŒä¸€ä¸ªä¼šè¯ä¸­æ··ç”¨ä¸åŒçš„è¯­è¨€ä»£ç 

## ä»€ä¹ˆæ˜¯ Interactive Sessionï¼Ÿ
Interactive Sessionæ˜¯Livyæä¾›çš„ä¸€ç§**é•¿æœŸè¿è¡Œçš„**, **æœ‰çŠ¶æ€çš„**Sparkä¼šè¯, å…è®¸ç”¨æˆ·é€šè¿‡REST APIäº¤äº’å¼åœ°æä¾›å’Œæ‰§è¡Œä»£ç 

### æ‰§è¡Œä»£ç 
```scala
  // InteractiveSession.scala
  def executeStatement(content: ExecuteRequest): Statement = {
    ensureRunning()
    recordActivity()

    val id = client.get.submitReplCode(content.code, content.kind.orNull).get
    val statement = client.get.getReplJobResults(id, 1).get().statements(0)
    // Send statement event to listeners.
    triggerStatementEvent(statement)
    statement
  }
```

 Interactive Sessioné€šè¿‡RSCClient (Remote Spark Context Client) ä¸è¿œç¨‹çš„Spark Driverå»ºç«‹RPCè¿æ¥, æäº¤ä»£ç åˆ°REPLè§£é‡Šå™¨æ‰§è¡Œ
 
 ```java
 // RSCClient.java
   public Future<Integer> submitReplCode(String code, String codeType) throws Exception {
    return deferredCall(new BaseProtocol.ReplJobRequest(code, codeType), Integer.class);
  }
  
// å‘Driveræäº¤ä»»åŠ¡
private <T> io.netty.util.concurrent.Future<T> deferredCall(final Object msg,  
    final Class<T> retType) {  
  if (driverRpc.isSuccess()) {  
    try {  
      return driverRpc.get().call(msg, retType);  
    } catch (Exception ie) {  
      throw Utils.propagate(ie);  
    }  
  }   
  // ...
  return promise;  
}
 ```

### ä¼šè¯çŠ¶æ€ç®¡ç†
```scala
// InteractiveSession.scala
  override def state: SessionState = {
    if (serverSideState == SessionState.Running) {
      // If session is in running state, return the repl state from RSCClient.
      client
        .flatMap(s => Option(s.getReplState))
        .map(SessionState(_))
        .getOrElse(SessionState.Busy) // If repl state is unknown, assume repl is busy.
    } else serverSideState
  }
```

- å¦‚æœçŠ¶æ€æ˜¯Running, è¿™ä¸ªæ—¶å€™è¿”å›çš„çŠ¶æ€ == RSCClientçš„çŠ¶æ€, å¦åˆ™è¿”å›serverSideState, 
- å¦‚æœçŠ¶æ€æ˜¯Running, ä½†æ˜¯RSCClientæ²¡æœ‰ç»™å‡ºæœ‰æ•ˆè¿”å›, è¿™ä¸ªæ—¶å€™å‡è®¾RSCClientçš„çŠ¶æ€æ˜¯Busy

### å¿ƒè·³æœºåˆ¶
```scala
// InteractiveSession.scala
  override protected val heartbeatTimeout: FiniteDuration = {
    val heartbeatTimeoutInSecond = heartbeatTimeoutS
    Duration(heartbeatTimeoutInSecond, TimeUnit.SECONDS)
  }
```

å¿ƒè·³æ£€æµ‹è‡ªåŠ¨æ¸…ç†äº†è¶…æ—¶çš„ä¼šç”»

### è¯­å¥ç®¡ç†
```scala
// InteractiveSession.scala

// è¿”å›æ‰€æœ‰çš„statement
  def statements: IndexedSeq[Statement] = {
    ensureRunning()
    val r = client.get.getReplJobResults().get(
      livyConf.getTimeAsMs(LivyConf.REQUEST_TIMEOUT), TimeUnit.MILLISECONDS)
    r.statements.toIndexedSeq
  }

// è·å–æŒ‡å®šIDçš„çš„statement
  def getStatement(stmtId: Int): Option[Statement] = {
    ensureRunning()
    val r = client.get.getReplJobResults(stmtId, 1).get(
      livyConf.getTimeAsMs(LivyConf.REQUEST_TIMEOUT), TimeUnit.MILLISECONDS)
    if (r.statements.length < 1) {
      None
    } else {
      val statement = r.statements(0)
      // Send statement event to listeners.
      triggerStatementEvent(statement)
      Option(statement)
    }
  }
```

æ¯ä¸ªæäº¤çš„è¯­å¥ç‰‡æ®µéƒ½ä¼šè¢«ä¸€ä¸ªstatementå¯¹è±¡å¯¹åº”, èƒ½ä»RSCClientä¸­è·å–è¿™ä¸ªStatement, è¯»å–åˆ°è¿™ä¸ªè¯­å¥çš„ä¿¡æ¯

### æ•´ä½“çš„æµç¨‹
æ•´ä½“çš„è®¿é—®æµç¨‹æ˜¯
Client -> Livy Server -> RSC Driver + REPL -> SparkContext
## Livy çš„æ ¸å¿ƒç»„ä»¶æœ‰å“ªäº›ï¼Ÿ

# åŸºæœ¬ä½¿ç”¨

1. å¦‚ä½•é€šè¿‡ REST API åˆ›å»ºä¸€ä¸ª Spark Sessionï¼Ÿ

- ğŸ” æ¢ç´¢ï¼šdocs/rest-api.mdï¼Œå°è¯•Â POST /sessions

1. å¦‚ä½•æäº¤ä¸€æ®µ Scala/Python ä»£ç æ‰§è¡Œï¼Ÿ

- ğŸ” æ¢ç´¢ï¼šPOST /sessions/{id}/statements

1. Session æœ‰å“ªäº›çŠ¶æ€ï¼Ÿå¦‚ä½•æŸ¥çœ‹å½“å‰çŠ¶æ€ï¼Ÿ

- ğŸ” æ¢ç´¢ï¼šGET /sessions/{id}ï¼Œè§‚å¯Ÿ state å­—æ®µ
